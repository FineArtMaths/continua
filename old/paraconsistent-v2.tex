\documentclass[oneside,english]{article} 
\usepackage[T1]{fontenc} 
\usepackage[latin9]{inputenc} 
\usepackage{amsmath} 
\usepackage{amstext} 
\usepackage{amsthm} 
\usepackage{amssymb}
\usepackage{mathrsfs} 
\usepackage{mathabx}
\usepackage{mathtools}

\makeatletter 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Textclass specific LaTeX commands. 
\theoremstyle{plain} 
\newtheorem{thm}{\protect\theoremname}   

\theoremstyle{definition}   
\newtheorem{defn}[thm]{\protect\definitionname}

\theoremstyle{definition}   
\newtheorem{prop}[thm]{\protect\definitionname}

\makeatother

\usepackage{babel}   
\providecommand{\definitionname}{Definition} 
\providecommand{\theoremname}{Theorem}


\begin{document}
	
	\title{Note on the Duality between Intuitionistic and Paraconsistent Logics}
	\author{Rich Cochrane}
	\date{\today}
	\maketitle

This note discusses a relationship between three kinds of logic: classical, intuitionistic and paraconsistent. Each of these corresponds to a class of algebraic structures. 

Throughout, it will be helpful to bear in mind the close relationship between $\cap$ in set theory and $\land$ in logic, and similarly between $\cup$ and $\lor$. This is especially clear in cases where each set is the set of objects satisfying some predicate, i.e.
\[
	P = \{x : p(x)\}
\]
Then we have
\[
	\begin{split}
		P\cap Q & = \{x : p(x)\land q(x)\}\\
		P\cup Q & = \{x : p(x)\lor q(x)\}
	\end{split}
\]
The material conditional and complementation require logical negation, and this is the area that is contested among the different logics discussed below. Making unproblematic definitions that are not circular is not at all straightforward -- for example, one cannot simply define
\[
	p(x)\rightarrow q(x) \Leftrightarrow \lnot p(x)\lor q(x) \Leftrightarrow x\in -P\cup Q
\]
without having a notion of complementation that gives the symbol `$-P$' meaning. In the next section we will develop these ideas further, producing simple set-theoretic models of different complementation regimes each of which arises naturally in real mathematics.

Note: The term `full complement', `anti-clopen' and the notations $\divdot$ and $\dotdiv$ are not standard. To preserve notational symmetry I have used $A-B$ for the relative complement of $B$ in $A$, i.e.
\[
	A-B = \{x : x\in A\land x\notin B \}
\]

\section{Philosophical Motivation}

Aristotle proposed three fundamental `laws of thought': the laws of Identity, Non-Contradiction and Excluded Middle. A logic that enforces all three universally will here be called a `classical logic'.

Much investigation has been done into what happens when one of these laws is dropped. The least-examined, as far as I know, is the consequences of dropping Identity. With it must go unrestricted substitution: if $a=b$ then $b$ may be freely substituted for $a$. My suspicion is that dropping this law produces something that does not look much like a logic, and in particular something incapable of producing proofs as we know them. But that might not be true.

When LEM and LNC are both in force they are equivalent to one another. When LEM is dropped we obtain the intuitionistic version of the classical logic we started with; when LNC is dropped we obtain the paraconsistent version. When both are dropped we obtain what I am calling the `weak' version of the logic. Philosophers are interested in asking which of these, if any, is the right one to choose. 

From a pragmatist perspective there can be no single logic that faithfully captures all rational human thought. Any claim to the contrary would require a proof, leading to either circularity (perform the proof in the logic we claim is correct) or infinite regress (what is the correct metalogic and can we prove \emph{its} correctness?). So the various logics are not engaged in a zero-sum contest: all may be useful, and a metamathematical (and semantic) question remains as to which is the most appropriate choice for a particular application.

However, in mathematics the choice of logic does matter. Consider $A$, an axiom system for classical analysis, and $B$ an axiom system for synthetic differential geometry. Under classical logic, the theory of $A$ is often considered too large to underwrite empirical theories. For example, it includes phenomena that occur in three-dimensional space but only at a single point, which do appear to be unobservable objects. 

This has led some philosophers to suggest that $A$ should be studied using a weaker logic, such as the intuitionistic one. But the suggestion has met with very little enthusiasm by mathematicians, who quite correctly see it as trying to do analysis with one hand tied up. Why study a weaker theory when a stronger one is available, as long as the stronger theory is non-trivial?

One solution is to replace $A$ with $B$. Unfortunately the theory of $B$ under classical logic is trivial -- that is, every sentence is a theorem. Thus, classical logic is too strong to study $B$ or, more picturesquely, $B$ is too fragile to be subjected to classical logic. On the other hand, the intuitionistic theory of $B$ is not trivial. Thus, perhaps intuitionistic logic is the correct choice when studying $B$, although it is possible that there is a stronger logic in between this and classical logic under which the theory of $B$ remains non-trivial.

Furthermore, it seems likely that $B$ could also be studied by paraconsistent logic. We expect that the resulting theory would overlap with the intuitionistic one but not be identical to it. Since intuitionistic and paraconsistent logics are dual to one another, we could expect a `reflection' to exist in the union of the two theories, fixing their intersection and permuting the other theorems across it. If so, the intuitionist should be able to find an axiom system $B^\prime$ whose intuitionistic theory is precisely the paraconsistent theory of $B$, and the map $B\to B^\prime$ can be expected to be a bijection that follows a simple symbolic rule. It may be that this `reflection' is not unique.

Classical logic, on the other hand, proves the union of the theorems proved by intuitionist and paraconsistent logics. We can therefore think of classical logic as an extension of each of these. These considerations lead us to postulate a kind of `Galois theory' of logics. Let $I$, $P$ and $C$ be theories proved from an axiom set by intuitionistic, paraconsistent and classical logics respectively. Write $[C:P]$ to express the fact that $C$ is an extension of $P$ and $[C:I]$ likewise. Then we would look for a group action on $C$ that fixes $P\cap I$ and permutes the elements of $P\Delta I$. This could be said to correspond to the group of translations that could be used to mediate between paraconsistent and intuitionistic logicians working on the same mathematical theory. (Finding such a group might be hard -- for example, it might be equivalent to solving the word problem for the algebras involved -- but modern Galois theory has a lot of techniques in its toolkit.)

Thus my position is that `choice of logic' between these four is not an interesting question in general, and that of more interest is the study of the whole lattice consisting of six logics:
\begin{itemize}
	\item The trivial logic in which all sentences are true.
	\item Classical logic, a level below that.
	\item Intuitionist logic, a level below again.
	\item Paraconsistent logic, at the same level.
	\item Weak logic, a level below.
	\item The trivial logic in which no sentence is true, at the lowest level.
\end{itemize}

(Perhaps the always-true logic may be characterised as Classical logic with its Law of Identity expanded to include not only $a=a$ but also $a=b$ for all $a$ and $b$; in particular from every $p$ we will be able to prove $p\land\lnot p$ and use the \emph{ad contradictione quodlibet} version of LNC to prove everything else. The always-false logic can then be thought of as Weak logic with its Law of Identity repealed entirely, i.e. $a\ne b$ for all $a$ and $b$, including $a\ne a$. But this is speculative, and in any case neither of these extremes is interesting in itself. It is possible that this is too simplistic and deductive rules derived from, e.g., relative identity may yield additional interesting logics.)

\section{Four Systems of Sets}

Suppose we are interested in making logical deductions about a one-dimensional continuum. We will refer to this as $\mathbb{R}$, the `real line', and use the fact that by marking a distinguished point on the line and choosing a unit of measurement and an orientation we can specify any point on the line using a single number. For concreteness we will make all of our definitions with reference to $\mathbb{R}$, although they can easily be made much more general. We will not require any results from analysis.

The standard notion of continuity of the real line is captured by a structure known as the `Euclidean topology\footnote{The Euclidean topology arises from a norm, and in any finite-dimensional vector space all such topologies are identical. Thus `Euclidean' is something of a misnomer, since the norms that arise from non-Euclidean geometries all give rise to the same topology. One in fact has to work quite hard to construct any other notion of continuity that might have geometric meaning.}'. This will be our main source of examples and is defined as follows.

\begin{defn}
	Let $S$ be any set. A \emph{topology} on $S$ is a subset $\mathscr{O} \subseteq 2^S$ such that:
	\begin{itemize}
		\item $S\in\mathscr{O}$ and $\emptyset\in\mathscr{O}$
		\item For every countable $X\subseteq\mathscr{O}$, $\bigcup X\in \mathscr{O}$ (i.e., $\mathscr{O}$ is closed under countable unions)
		\item For every finite $X\subseteq\mathscr{O}$, $\bigcap X\in \mathscr{O}$ (i.e., $\mathscr{O}$ is closed under finite unions)
	\end{itemize}
\end{defn}

Note the asymmetry between unions and intersections -- countably infinite unions are guaranteed to exist but infinite intersections are not. This will be of great importance. The intuition here is that, in classical analysis, an infinite intersection may resolve to a single point, which is not open.

We will construct a topology on the real line from `open intervals', which plausibly correspond to the sites of possible empirical observations with a margin of experimental error. the intuition here is that when we make an observation `at a point', we in fact do so over a small region.

\begin{defn}
	Let $\mathbb{R}$ be the set of points making up a continuous line, which we will refer to by numerical coordinates. For any pair $a, b$, $a < b$, we have an \emph{open interval}
	\[
		(a, b) = \{r\in\mathbb{R} : a < r < b\}
	\]
\end{defn}

From these open intervals we generate a topology:

\begin{defn}
	The \emph{Euclidean topology} on $\mathbb{R}$ is the topology generated by its open intervals. That is, $(a, b)\in\mathscr{O}$ and $\mathscr{O}$ is closed under countable unions and finite intersections. The elements of $\mathscr{O}$ are called the \emph{open sets} of the topology.
\end{defn}

Note in particular that $\mathbb{R}\in\mathscr{O}$ because, for example,
\[
	\mathbb{R} = \bigcup_{z\in\mathbb{Z}} (z-1, z+1)
\]
thanks to the existence of \emph{countable} unions of open intervals. For the same reason we have all infinite open intervals of the forms $(-\infty, r)$ and $(r, \infty)$.

Also, $\emptyset\in\mathscr{O}$ because, for example,
\[
\emptyset = (0, 1)\cap (2, 3)
\]

\subsection{Open Complementation}

It often makes sense to limit our theories to speaking only about open sets. For example, if an empirical observation is always made within a margin of error $\epsilon$, any observation of a `point' $r$ will always be an observation of an open interval $(r-\epsilon, r+\epsilon)$. Furthermore, open sets are the natural domain of definition for derivatives in the calculus.

Thus far we can express logical conjunction and disjunction of such observations by means of intersections and unions of open sets. We would like to extend this idea to express negation, i.e. $\lnot(x\in U)$, which requires a corresponding notion of set-complementation. Unfortunately the usual set-theoretic complementation is too strong, since $\mathscr{O}- U$ need not be an open set.

To recover a notion of complementation that is more consistent with restricting our attention to open sets we adopt the `open complement', which intuitively ought to be the largest open set whose intersection with $U$ is empty. 
\begin{defn}
	Let $S$ be any subset of $\mathbb{R}$. Its \emph{interior}, written $\text{int}(S)$, is 
	\[
		\text{int}(S) = \bigcup \{U\in \mathscr{O} : U\subseteq S\}
	\]
\end{defn}
Note that for any set, its interior is an open set and intuitively it is the largest open set contained within it. This helps us to define a more natively topological notion of complementation, which we call the \emph{open complement}. Let $U = (-\infty, 0)$. The set-complement is
\[
	\mathbb{R}- (-\infty, 0) = [0, \infty) = \{r\in\mathbb{R}: r \ge 0\}
\]
but this is not an open set. Instead we define
\[
	A\dotdiv B = \text{int}(A- B)
\]
For example:
\[
	\mathbb{R}\dotdiv (-\infty, 0) = \text{int}(\mathbb{R}- (-\infty, 0)) = (0, \infty)
\]
This operation works between any pair of sets in $\mathbb{R}$ and always returns an open set. For short we write $\dotdiv S$ for $\mathbb{R}\dotdiv S$, the complement of $S$ in the whole space.

Note that in general $S\cup\dotdiv S\ne \mathbb{R}$ -- or in logical terms, $p\lor\lnot p$ is not necessarily true. Thus topology with `open complementation' is `intuitionistic' in a sense to be made precise below.

\subsection{Closed Complementation}

This section considers topology from a dual perspective. Instead of looking at open sets only, we limit our attention to closed sets. These are the natural domain of definition for integrals in calculus. It turns out that we can define a topology by its closed sets rather than its opens (the term):

\begin{defn}
	Let $S$ be any set. The subset $\mathscr{O}^c \subseteq 2^S$ of \emph{closed sets} is such that:
	\begin{itemize}
		\item $S\in\mathscr{O}^c$ and $\emptyset\in\mathscr{O}^c$
		\item For every finite $X\subseteq\mathscr{O}^c$, $\bigcup X\in \mathscr{O}^c$ (i.e., $\mathscr{O}^c$ is closed under finite unions)
		\item For every countable $X\subseteq\mathscr{O}^c$, $\bigcap X\in \mathscr{O}^c$ (i.e., $\mathscr{O}^c$ is closed under countable unions)
	\end{itemize}
\end{defn}

Note that, despite the terminology, a set may be both open and closed -- easy examples are $\mathbb{R}$ and $\emptyset$ -- and that a subset of $\mathbb{R}$ may be neither. The jargon for a set that belongs to both $\mathscr{O}$ and $\mathscr{O}^c$ is \emph{clopen}, and we will return to clopen sets later.

Of course, we would like to develop a notion of negation that makes sense for closed sets. Again, full complementation is not appropriate. For example, $(-\infty, 0]$ is a closed set but
\[
	\mathbb{R}- (-\infty, 0] = (0, \infty) = \{r\in\mathbb{R}: r > 0\}
\]
is not closed. We proceed in a manner that is perfectly dual to that of the previous section.

\begin{defn}
	Let $S$ be any subset of $\mathbb{R}$. Its \emph{closure}, written $\overline{S}$, is 
	\[
	\overline{S} = \bigcap \{C\in \mathscr{O}^c : S\subseteq C\}
	\]
\end{defn}

This allows us to define \emph{closed complementation} as follows:
\[
	A\divdot B = \overline{A- B}
\]
For example,
\[
	\mathbb{R}\divdot (-\infty, 0] = \overline{\mathbb{R}- (-\infty, 0]} = [0, \infty)
\]
This operation works between any pair of sets in $\mathbb{R}$ and always returns a closed set. For short we write $\divdot S$ for $\mathbb{R}\divdot S$, the complement of $S$ in the whole space.

Note that in general $S\cap\divdot S\ne \emptyset$ -- or in logical terms, $p\land\lnot p$ is not necessarily false. Thus topology with `closed complementation' is `paraconsistent' in a sense to be made precise below.

\subsection{Clopen and Anti-Clopen Systems of Sets}

TODO: Check all this, some of it is probably wrong.

\begin{defn}
	The \emph{clopen sets} of a topological space are the elements of $\mathscr{O}\cap \mathscr{O}^c$, i.e. those that are both open and closed. 
\end{defn}
Unfortunately in the case of $\mathbb{R}$ the only examples are $\emptyset$ and $\mathbb{R}$ itself, but other topological spaces have richer systems of clopen sets.

The following theorem is obvious and makes the connection with the systems of open and closed sets we have considered in the previous sections:
\begin{thm}
	\begin{itemize}
		\item $S\in\mathscr{O}\cap \mathscr{O}^c$ and $\emptyset\in\mathscr{O}\cap \mathscr{O}^c$
		\item For every finite $X\subseteq\mathscr{O}\cap \mathscr{O}^c$, $\bigcup X\in \mathscr{O}\cap \mathscr{O}^c$ (i.e., $\mathscr{O}\cap \mathscr{O}^c$ is closed under finite unions)
		\item For every finite $X\subseteq\mathscr{O}\cap \mathscr{O}^c$, $\bigcap X\in \mathscr{O}\cap \mathscr{O}^c$ (i.e., $\mathscr{O}\cap \mathscr{O}^c$ is closed under finite intersections)
	\end{itemize}
\end{thm}

Full complementation works perfectly well in systems of clopen sets: since the complement of a closed set is open and the complement of an open set is closed, it follows that the complement of a clopen set is clopen. Furthermore, it is obvious that
\[
	A\dotdiv B = A - B = A\divdot B
\]
so that open, closed and full complementation become identical.

We have seen that a system of clopen sets imposes finitude on both intersections and unions, whereas open or closed systems impose it on only oe or other. It is natural to consider systems of sets in which finitude is not imposed on either operation, i.e.
\begin{defn}
	The \emph{anti-clopen sets} of a topological space are the elements of $\mathscr{O}\cup \mathscr{O}^c$, i.e. those that are either open or closed.
	\begin{itemize}
		\item $S\in\mathscr{O}\cup \mathscr{O}^c$ and $\emptyset\in\mathscr{O}\cup \mathscr{O}^c$
		\item For every countable $X\subseteq\mathscr{O}\cup \mathscr{O}^c$, $\bigcup X\in \mathscr{O}\cup \mathscr{O}^c$ (i.e., $\mathscr{O}\cup \mathscr{O}^c$ is closed under countable unions)
		\item For every countable $X\subseteq\mathscr{O}\cup \mathscr{O}^c$, $\bigcap X\in \mathscr{O}\cup \mathscr{O}^c$ (i.e., $\mathscr{O}\cup \mathscr{O}^c$ is closed under countable unions)
	\end{itemize}
\end{defn}
Such structures are usually called \emph{sigma algebras} and are of fundamental importance in measure theory and probability. Their elements are also called Borel sets and when generated from a topological space in the way just described they are known alternatively as the \emph{Borel algebra} of the space.

The system of anti-clopen sets of a topological space is obviously much larger than the system of clopen sets, and this leaves `enough room' for open and closed complementation to coexist since in general
\[
	A\dotdiv B \ne A\divdot B
\]
For example, consider $A = (-2, 0)$, $B = [-1, 1]$:
\[
	\begin{split}
		A\dotdiv B &= \text{int}(A- B) = (-1, 0) \\
		A\divdot B &= \overline{A- B} = [-1, 0]
	\end{split}
\]
Following our previous observations, this suggests an association with a very weak logic in which neither the Law of Non-Contradiction nor the Law of the Excluded Middle is in force.

\subsection{Distributive Laws in the Four Systems}

In this section we consider the fate of some standard laws of classical set theory when applied to the algebras of sets discussed above. To do so, we introduce a new notation whose relation to logical notation is no coincidence.

In set theory we have the finite distributive laws
\[
	\begin{split}
		P\cap (Q\cup R)  &= (P\cap Q)\cup (P\cap R) \\
		P\cup (Q\cap R)  &= (P\cup Q)\cap (P\cup R) 
	\end{split}
\]
In logic we have corresponding distributive laws
\[
	\begin{split}
		p\lor (q\land r)  &= (p\lor q)\land (p\lor r) \\
		p\land (q\lor r)  &= (p\land q)\lor (p\land r) 
	\end{split}
\]
We would like to extend these to infinite families of sets (or, correspondingly, propositions) but depending on the structure available to us this is not always possible.

To explore this further we introduce the notions of `meet' and `join' in a system of sets. This may initially look like a mere change of notation:
\begin{defn}
	Let $S$ be a set and $A\subseteq 2^S$ a collection of its subsets. Then for $X, Y\in A$ we write: 
	\begin{itemize}
		\item $X\land Y$ for the \emph{meet} of $X$ and $Y$, defined as the element of $A$ such that $X\land Y\subseteq X$, $X\land Y\subseteq Y$ and that is a superset of any other element of $A$ that satisfies these two criteria.
		\item $X\lor Y$ for the \emph{join} of $X$ and $Y$, defined as the element of $A$ such that $X\subseteq X\lor Y$, $Y\subseteq X\lor Y$ and that is a subset of any other element of $A$ that satisfies these two criteria.
	\end{itemize}
\end{defn}
In this context we sometimes also write $X\le Y$ for $X\subseteq Y$, but one also sees $X\Leftarrow Y$ or even $Y\vdash X$ to make a further connection with logic. Here we will continue to use `$\subseteq$' as our examples will continue to be concrete algebras of sets.

These notations are extended in the obvious way to cover meets and joins of (finite or infinite) families of sets. If $F_1, F_2, \dots$ is a family of sets, we have
\[
	\bigwedge_n F_n \ \text{and} \ \bigvee_n F_n
\]
Given the definitions of the systems of sets we have been considering, our main focus will be on the meets and joins of countably infinite families of sets. In a system of anti-clopen sets these definitions are indeed rather trivial, since meets always coincide with intersections and joins with unions. Because of this, in that context we can define the infinite distributive laws
\[
	\begin{split}
		A\land \bigvee_n F_n & = \bigvee_n A\land F_n \\
		A\lor \bigwedge_n F_n & = \bigwedge_n A\lor F_n 
	\end{split}
\]
Things are more interesting -- and less convenient -- in the other cases.

Consider first the case of topology (the system of open sets), and specifically the family of sets
\[
	F_n = (\frac{-1}{n}, \frac{1}{n}) \ \text{for all} \ n\in\mathbb{N}
\]
In set-theoretic terms we have
\[
	\bigcap_n F_n = \{0\}
\]
but this is not an open set (and that is legal, because the axioms of topology do not guarantee the inclusion of countable intersections). In fact we have
\[
\bigwedge_n F_n = \emptyset
\]
Thus, intersection and meet behave differently. On the other hand, in a topology countable unions and meets do always agree. This allows us to construct an infinite distributive

For example, $A = (-\infty, 0)\cup(0, \infty)$, which is an open set. Then:
\[
		A\land \bigvee_n F_n = (-1, 1) = \bigvee_n A\land F_n \\
\]
so that the first infinite distributive law holds, but
\[
		A\lor \bigwedge_n F_n = \emptyset \ne \mathbb{R} = \bigwedge_n A\lor F_n 
\]
so that the second infinite distributive law fails rather dramatically. In general, in a system of open sets we can expect only the `distributive law over infinite joins' to be in force, not the `distributive law over infinite meets'.

We should not be surprised to find the exactly dual situation in systems of closed sets. Here, join distributes over infinite meets (which are guaranteed to be equal to infinite intersections of sets) but meet need not distribute over infinite joins (which might nto be equal to infinite unions of sets).

As a concrete example, let $F_n = [-\frac{1}{n}, \frac{1}{n}]$, so that 
\[
	\bigvee_n F_n = [-1, 1]\ne (-1, 1) = \bigcup_n F_n
\]
and let $A = (-\infty, -1]\cup[1, \infty)$. Then
\[
	A\lor \bigwedge_n F_n = (-\infty, -1]\cup \{0\}\cup [1, \infty) = \bigwedge_n A\lor F_n 
\]
so that the second infinite distributive law holds, but
\[
	A\land \bigvee_n F_n = \mathbb{R} \ne  = \{-1, 1\} = \bigvee_n A\land F_n \\
\]
so that the first infinite distributive law fails.  

Furthermore, in the system of clopen sets both identities may fail to hold, again because the infinite unions and intersections do not necessarily agree with infinite meets and joins. 

Rather than speaking of infinite unions and intersections `existing', it will be more convenient to ask whether these two distributive laws are guaranteed to hold. This will also bring us closer to the logical interpretation of systems of sets.

\section{Lindenbaum-Tarski Algebras}

The previous section introduced systems of open, closed, clopen and anti-clopen subsets of a set, with examples drawn from standard subsets of $\mathbb{R}$. We now clarify the sense in which these are intimately related to logics.
\begin{defn}
	Let $S$ be the set of all sentences (i.e. wffs without free variables) expressible in a given formal language. Then we say $a, b\in S$ are \emph{logically equivalent} and write $a\cong b$ iff $a\vdash b$ and $b\vdash a$.
\end{defn}
The differences between the logics we are considering relate to their deductive strength. Thus, we are not interested in distinguishing between logically equivalent sentences. It makes sense to collapse such distinctions and consider only the equivalence classes of sentences. 
\begin{defn}
	Let $a$ be any sentence. The set
	\[
		\{b\in S : a\cong b\}
	\]
	is called the \emph{logical equivalence class} of $a$.
\end{defn}
From now on by a slight abuse of notation we will simply write $a$ for the class of all sentences logically equivalent to $a$. Since we never need to refer to individual sentences within a class, this will not lead to confusion.

We always have at least two equivalence classes: $\top$, the class of tautologies, and $\bot$, the class of absurdities. Under any assignment of truth-values to variables in the language, the sentences of $\top$ evaluate true and those of $\bot$ evaluate false.

\subsection{The Boolean Algebra of a Classical Theory}

The following is intended to look familiar (compare it with the system of anti-clopen sets defined above):

\begin{thm}
	Suppose that $S$ is the set of all (equivalence classes of) sentences a formal language. Then:
	\begin{itemize}
		\item $\top\in S$ and $\bot\in S$
		\item For every countable $X\subseteq S$, $\bigwedge X\in S$
		\item For every countable $X\subseteq S$, $\bigvee X\in S$
	\end{itemize}
\end{thm}
We also have the following distributive laws, where $F_1, F_2, \dots$ is a finite set of sentences:
\[
	\begin{split}
		p\lor\bigwedge_n F_n &= \bigwedge_n p\lor F_n \\
		p\land\bigvee_n F_n &= \bigvee_n p\land F_n
	\end{split}
\]
We would like to define a negation operation -- that is, for every $p$ we want to be able to identify another equivalence class of sentences that we will label $\lnot p$ and that has suitable behaviour. Since we are modelling classical logic, `suitable behaviour' means obeying both the Law of Non-Contradiction:
\[
	p \land \lnot p = \bot
\]
and the Law of the Excluded Middle:
\[
	p \lor \lnot p = \top
\]
The structure of (equivalence classes of) sentences equipped with the usual conjunction and disjunction, if it also has a negation matching these two criteria, is a \emph{Boolean algebra}. A simple calculation shows that when such a negation exists it must be unique. 

We call the resulting object -- the equivalence classes of sentences equipped with conjunction, disjunction and negation -- the \emph{Lindenbaum-Tarski algebra} of our theory. In this case it has the abstract structure of a Boolean algebra and the logic in force is classical, since the laws of negation just described are the Law of Non-Contradiction and the Law of the Excluded Middle, respectively.

(A potential source of confusion arises in relation to Stone's Representation Theorem, which states that Boolean algebras are isomorphic to the \emph{clopen} (not anti-clopen) sets of some topological space. However, such a `Stone space' must be compact and disconnected. In our examples we are considering the more familiar case of $\mathbb{R}$ with the Euclidean topology, which has neither property. Thus for our example the anti-clopen sets provide the right model, but there is nothing magical about the anti-clopen property in general that connects it to Boolean algebras.)

\subsection{The Heyting Algebra of an Intuitionistic Theory}

We now ask what happens if we restrict the previous definition to allow
\begin{itemize}
	\item For every \emph{finite} $X\subseteq S$, $\bigwedge X\in S$
\end{itemize}
The result should be a \emph{Heyting algebra}, but as we will see some work needs to be done before an official definition can be given.

The semantic motivation for this comes from a desire for `truth' in our logic to model something like `provability', `verifiability' or `observability'. In that case it will treat infinite disjunctions and conjunctions differently. It is isomorphic to the fragment of model logic that deals only with necessity, for we do not in general have $\square p\lor\square\lnot p$.

To prove $p_1\lor p_2\lor p_3\lor \dots$ one need only prove one of the $p_i$. Thus, even an infinite string of disjunctions, \emph{if true}, is provable in a finite amount of time. For example, if a theorem about prime numbers says there is at least one that has some property, we may express this using the infinite disjunction above by writing the proposition `the $i^{\text{th}}$ prime has the property' as $p_i$. Now we simply go through each prime in turn testing for the property -- if the statement is true, we will eventually find one and can stop the process.

On the other hand, suppose the theorem says that \emph{every} prime has a certain property, encoded this time as a conjunction $p_1\land p_2\land p_3\land \dots$ where $p_i$ means `the $i^{\text{th}}$ prime has the property'. To verify this statement requires us to check that $p_i$ is true for every prime, which is an infinite task -- at least, assuming no special technique, such as induction, can be made to work by reducing the infinite conjunction to a finite one. 

We would like to capture this by guaranteeing infinite disjunctions their own independent existence as `verifiable propositions'. Irreducibly infinite conjunctions, on the other hand, should continue to evaluate to $\bot$, which is semantically interpreted as `not finitely provable'. To be clear, we do not say that infinite conjunctions are not \emph{permitted} to have a separate existance from $\bot$, simply that this is not \emph{required}; infinite disjunctions, which all have the property of being verifiable in finite time, should be guaranteed their own existence.

On its own, however, this amendment to classical logic has no effect. De Morgan's Laws allow us to rewrite this second theorem in terms of an infinite disjunction:
\[
	\bigwedge_{i\in\mathbb{N}} p_i = \lnot \bigvee_{i\in\mathbb{N}} \lnot p_i
\]
Thus every infinite conjunction is logically equivalent to an infinite disjunction (and \emph{vice versa}, of course). It seems that admitting one infinity commits us to both.

One way to rescue the situation is to amend our definition of negation, which will lead to the immediate repeal of de Morgan's Laws. This blocks the transformation just described. But we will need to find the `right' definition of negation. Of course, we expect it to be analogous to open complementation in topology but this does not provide a direct route to a definition.

Let us begin by considering distributivity. Pairwise, we always have
\[
	\begin{split}
		p\land(q_1\lor q_2) &= (p\land q_1)\lor (p\land q_2) \\
		p\lor(q_1\land q_2) &= (p\lor q_1)\land (p\lor q_2)
	\end{split}
\]
which just looks like the rule for `multiplying out brackets' learned at school. In a Boolean algebra this extends to infinite families of sets:
\[
	\begin{split}
		p\land\bigvee_{i\in Q} q_i &= \bigvee_{i\in Q} p\land q_i \\
		p\lor\bigwedge_{i\in Q} q_i &= \bigwedge_{i\in Q} p\lor q_i
	\end{split}
\]
If we guarantee the existence of all infinite disjunctions but not of infinite conjunctions, on the other hand, the first of these remains innocent but the second is too strong. In the first case the infinite disjunctions on both sides exist by fiat, but in the second it could well happen that the infinite conjunction on one side exists, while the one on the other side does not. 

Thus we can hope for a negation operation, written `$\dotdiv$', that obeys the Law of Non-Contradiction:
\[
	p \land \dotdiv p = \bot
\]
but for which the Law of the Excluded Middle may sometimes fail:
\[
	p \lor \dotdiv p = \top \ \text{(not guaranteed!)}
\]
Note that in specific cases the identity of LEM might be satisfied, even with infinite families of sets; it is just not guaranteed.

\subsection{The Co-Heyting Algebra of a Paraconsistent Theory}

It is isomorphic to the fragment of model logic that deals only with possibility, for we may have $\lozenge p\land\lozenge\lnot p$.

\subsection{The Bi-Heyting Algebra of a Paraconsistent-Intuitionist Theory}

In a Boolean algebra, in which we affirm both LEM and LCC, we obtain a Boolean negation that makes LEM and LCC equivalent. We can define both the Heyting negation and the co-Heyting negation but each becomes equivalent to the Boolean negation so the distinction is not interesting.

A Classical theory is the union of its corresponding intuitionist and paraconsistent theories (since any classical proof involving both LEM and LNC can be recast to use only one of them). We are now interested in exploring the intersection: the theory given by the axiom system under the classical logic with LEM and LNC both removed.

Here both forms of negation coexist and are distinct; they do not collapse into a classical negation (which does not exist here). The resulting Lindenbaum-Tarski algebra must be both Heyting and co-Heyting, and is therefore called a bi-Heyting algebra. As an aside, note that the strongest algebraic structure characterises the weakest theory, and \emph{vice versa}. It would be convenient if this structure could be shown to be a Hopf algebra (with underlying field $\mathbb{Z}/2\mathbb{Z}$).

I believe this is isomorphic to a fragment of propositional modal logic, possibly one in which every atomic proposition is prefixed with either $\square$ or $\lozenge$. (This needs to be worked out in detail.)

\section{Topos and Complement-Topos}

The general idea here is that every topos has a `natural' intuitionistic logic, and an associated complement-topos whose natural logic is its paraconsistent dual.

TODO: Summarize the Strada-GOnzalez article from Koslow and Buchsbaum Vol 2.

\subsection{Connections with Quantum Theory}

(This part comes from parts of Flori's book)

In classical mechanics we have a state space $S$, and physical properties are scalar fields $f:S\to \mathbb{R}$ on the state space. Observational possibilities are open sets -- i.e. I measure that the property is in an open interval $\Delta$ and conclude the physical system is in one of the states in $f^{-1}(\Delta)$.

To provide a convenient framework for this we form the Boolean algebra $\text{Sub}(S)$ of all subsets in $S$ and let a state of the system be a map $\text{Sub}(S)\to \mathbb{2}$, i.e. a map that assigns `true' to a subset on which the state holds and `false' when it doesn't. Identifying sentences with states, we arrive at the Boolean model of classical logic.

In QM we are working with a Hilbert space $H$ (the state space) and its bounded operators $B(H)$, which form a \emph{non-commutative} algebra. This non-commutativity is what distinguishes classical and quantum theories. 

However, we can pay attention to sub-algebras of $B(H)$ that are commutative (specifically, spectral algebras). These are sometimes called `contexts', and they form a category of commutative algebras. That is, the morphisms must presevre commutativity and it turns out this means the only morphisms are inclusions -- i.e., the topos is a lattice of sets. 

As long as we stay within one of these sub-algebras, QM behaves classically. That is, each `thing' in QM is defined as a collection of descriptions, each of which is only guaranteed to work within its own `context' (sub-algebra). Specifically, a context is an abelian von Neumann sub-algebra; the collection of these is a category, $V(H)$, with inclusion maps the only morphisms.

So this is a kind of `classical localization' or `local approximation' (but in what sense?) of QM. Of course, we expect to be able to `paste together' these local pictures to recover the global one. Thus we are interested in some kind of (pre)sheaves over commutative sub-algebras of $B(H)$. The `state space' then becomes a presheaf called the spectral presheaf which, for each context V, assigns its Gel'fand spectrum (whatever that is).

We form our topos as follows. Let $C$ be a category, and $C^{op}$ its opposite (i.e. the same category except with all arrows reversed). Now consider covariant functors $C^{op}\to\text{Set}$ that assign each object in $C$ to a set and each morphism to a map of sets. (Equivalently, we may consider it to be the set of all contravariant functors from $C$.)

The category of all such functors is $\text{Set}^{C^{op}}$ -- the morphisms here are natural transformations. This category is a topos, and is the category of presheaves over $C$. So an object of $\text{Set}^{C^{op}}$ represents a way to map every subalgebra in $C$ to a set in a way that preserves (and reverses) set-inclusion -- we expect that reversal because, in a sheaf, bigger sets tend to have smaller fibres, i.e. you can usually say fewer true things about a big set than a small one.

Propositions are now identified with clopen sub-objects of the spectral pre-sheaf. These are technical but they are analogous to classical propositions of the form `the observation is in $\Delta$'. Note that for technical reasons the clopen sets form a Heyting algebra, not a Boolean one.

\section{Alternative Models of Continuity}

\subsection{Paraconsistent Calculus}

In general, paraconsistent approaches to the continuum seek to take `change at a point' seriously without falling foul of Zeno's arrow: change must really happen at a point and in an instant without any `thickening' of either into a micro-continuum (as is done in synthetic approaches). This is then a kind of `hyper-analytic geometry' that aims to preserve the metaphysical picture of the classical continuum.

Let $f:\mathbb{R}\to \mathbb{R}$. The derivative $df/dt$ is defined as
\[
	\lim_{dt\to 0} \frac{f(t + dt) - f(t)}{dt}	
\]
The limit exists if the left- and right-hand limits exist and are equal; in standard definitions of the derivative $f$ is also required to be continuous. 

Let us consider a simple example:
\[
	\begin{split}
		f(t) &= 
			\begin{cases*}
				2t & if $t < 0$ \\
				3t & otherwise
			\end{cases*}
	\end{split}
\]
Clearly $f|_(-\infty, 0)$ has constant derivative $df/dt = 2$. Furthermore, $f|_(0, \infty)$ has constant derivative $df/dt = 3$. Finally, $f$ is continuous at every point in the domain.

In particular, $f$ is continuous at $0$. Taking the limit from the left suggests that $df/dt = 2$ while taking it from the right yields $df/dt = 3$. This easily produces the conclusion that $2 = 3$, a contradiction, and so classically it is said that $df/dt$ does not exist here.

If we are committed to `change at a point and in an instant', and to the reasonableness of $f$ as defined, we seem to be committed to the existence of a derivative at $0$ and ought to be able to say what its value is. Another way to say this is that we should think of $df/dt$ as a function defined on all of $\mathbb{R}$, whose value is $2$ when $t < 0$ and $3$ when $t > 0$; the challenge is to agree on the value at 0 so that $df/dt$ is continuous.

An approach is suggested by Priest and expanded by Mortensen. Here we aim to, in effect, accept that $df/dt = 2$ and $df/dt = 3$ without the rest of our arithmetic collapsing. It is claimed that a paraconsistent approach makes this possible, suggesting that at $0$ there is a kind of `transition state' at which both derivatives exist at once.

Mortensen makes an effort to describe how this can be done by (I think) quotienting the tangent plane at $(0, 0)$ to turn it into a kind of tube or segment, so that $2 = 3$ does not contaminate any other arithmetic. It doesn't look as if it works but it's not expressed clearly enough to be sure about. In the end my question here is: What is Mortensen trying to achieve? What question is he trying to answer, or what phenomenon is he trying to model?

It seems that this idea has not been taken up by many writers since it was put forward, which makes me suspect there's not much in it as an alternative model of the continuum.

\subsection{Synthetic Differential Geometry}


\section{Notes from Contradiction Conference}

\subsection{Priest}

Paraconsistent logic is motivated by denying \emph{ex falso quodlibet} (EFQ) or what Priest calls `explosion'. 
\[
	p, \lnot p \vdash q \ \text{for all $q$}
\]
There are really two responses -- what Simon called `implosion':
\[
	p, \lnot p \vdash q \ \text{for no $q$}
\]
or Priest's preferred option, which is the standard paraconsistent approach:
\[
	p, \lnot p \vdash q \ \text{for some, but not all, $q$}
\]

The history of non-contradiction is quiet odd. For example, consider the syllogism
\begin{enumerate}
	\item No A is a B
	\item Some B is an A
	\item All A are A
\end{enumerate}
This is not a valid syllogism, but if explosion were in force then it would be, since it draws a conclusion from contradictory premises. Hence syllogistic logic might be said to be paraconsistent (in a weak sense because it's informal).

The `preface paradox' goes as follows. Suppose I write a book that makes a series of assertions $A_1, ..., A_n$. I also write a preface in which I admit the book almost certainly contains at least one mistake. I assert the truth of each $A_i$ individually, but I assert $\lnot(A_1\land ...\land A_N)$. This seems reasonable, but it means my theory is inconsistent. Perhaps conjunction doesn't always preserve truth-values, just as intersection doesn't always preserve openness in topology.

The `disjunctive syllogism' is where EFQ comes into the tradition, probably via William of Soissons in the C12. It becomes known as `William's machine'. In ther Early Modern period there is really no continuous tradition of logic (allegedly -- not convinced this is true, although projects like philosophical languages don't much look what philosophers think of as `logic').

Of course, formal logics only arise in the C19, and paraconsistent versions begin to be explored in the 1960s/70s by Jaskowski, da Costa, Anderon and Belnap and others. Priest claims there are many paraconsistent logics but only one intuitionist logic -- this seems false to me, but perhaps he means `multiple traditions'.

You can use paraconsistent logic without being a dialethist. For example, you might use it to work with infinitesimals, which can be simultaneously equal to and unequal to zero. But you aren't thereby committed to a belief that infinitesimals really exist. It may just be that your theory has a subtheory that has no infinitesimals in it and this can indeed refer to the real world, which looks very much like what was going on (same for complex numbers).

An intuitionist can say the Liar sentence is neither true nor false, and that works fine. But what about `This sentence is either false or (neither true nor false)'? A dialethist can't be caught out in this way. These paradoxes don't interest me much but it's a fair point.

A Quinean charge: If you change the logic, you change the theory. I think this is true. Priest rejects it, saying logic should be able to deal with real-world phenomena that can't be changed by fiat (by changing the logic). But such phenomena are very rarely formalizable, if ever, and argumentative dialogues about them are never carried out in formal languages.

Contraries vs contradictories. For example, `red' and `green'. Something can be neither, but can't be both (this is a contrary). No need for paraconsistent logic here though -- everyone can agree this happens because `green' isn't equivalent to `not red'.

Lakotos wrote a paper on the rise of epsilon-delta methods in analysis, suggesting it came about because of problems with uniform convergence that revealed deeper misunderstandings about how quantifiers work.

\subsection{My Thoughts}
	
There is an absolute difference between formal and informal reasoning. 

In a formal system you should choose your axioms so that the strongest logic that doesn't make the theory collapse yields the theory you want. If it doesn't, change your axioms, not your logic. You can probably re-axiomatise and get the same theory from a different logic -- but not just \emph{any} logic.

In the case of informal reasoning, formal logic is at best an analogy or story we tell to help us negotiate social norms. I think Novaes is right that informal reasoning is ineliminably social. 

\subsection{Catarina Dutilh Novaes}

This talk was about the role of contradiction in ancient Greek dialectic. Here exposing your opponent by making them assert a contradiction is a matter of humiliating them in front of an audience (\emph{elenchus}). A contradiction in their speech doesn't lead to an explosion -- in fact it leads us to believe \emph{nothing} that person has to say is true.

The specificty of this dialogue is important. In principle I can contradict something I said yesterday in a different dialogue. For instance, if today I'm a lawyer and I say `X is innocent' but I go home to my wife and confess `X is guilty' these are different contexts and I haven't necessarily commited an absurdity (it's proper for me to defend X in court, and for me to be honest with my wife at home).

This leads perhaps to a local theory of contradiction -- the question is something like `what is the largest scope I can expand this utterance to and still be consistent?' -- not whether I am consistent across all times and places. It seems that a sheaf is lurking here somewhere, and a cohomology theory describing obstructions to global consistency.

Perhaps memory is also important here -- someone has to know that I said the two contradictory things, and recall them. Temporality ceases to be so important in mathematics but the essential social context of assertion perhaps doesn't.

Catarina mentioned a book to me by someone maybe called Gil Harman called something like\emph{changes in meaning}.
	
\subsection{Alexander Douglas}

In a letter, Spinoza wrote that `all determination is negation' in relation to a question about geometry (specifically, about shape). All that exists is infinite space; a shape is something we make by negating everything outside it. This is worth looking at, especially in relation to Aristotle's continuum and pointfree topology.

Some problems arise from the transitivity of identity -- we want to say that $a=b$ and $b=c$ but $a\ne c$, as for example in Abelard's account of the trinity. Paraconsistent logic can enable us to do this -- Priest discusses this in a recent book called \emph{One}.

Possibly interesting, but tangential -- Donald Baxter's discussion of Medea, who at once holds contradictory desires (to kill her children and not to kill them). This is a possible example of non-temporal contradiction, although it seems to be essentially private.

\subsection{Simon Hewitt}

Rumfitt (sp?) `bilateral' logic of assertion and denial seems a good way to formalise Novaes's idea. Effectively, you can't assert and deny $p$, and the criteria for asserting that $p$ are precisely those for denying that $\lnot p$. But the criteria for asserting $p$ and those for asserting $\lnot p$ might both be satisfied, so that asserting $\lnot p$ is not the same as denying $p$. This is part of a wider project bringing in social epistemology and accounts of reason-giving.

\section{Sheaves Example}

\subsection{Local Inconsistency}

The following setup is what we will formalise using sheaves. It is based on an informal, pragmatic approach to inconsistency and does not require any assumptions about underlying logic.

Write $p|_t$ for an assertion logically equivalent to $p$ made at time $t$. We presume that it is not unknown for there to be, for any given person, a $p$ and $t, t^\prime$ such that $p|_t$ and $(\lnot p)|_{t^\prime}$. There is also a natural measure of distance between assertions, namely the interval that elapsed between them:
\[
	d(p|_t, q|_{t^\prime}) = |t - t^\prime|
\]

Suppose that Jones is testifying in a law court between 10am and 11am one day. Jones will be concerned to know whether she made any inconsistent statements during this time. Modulo logical equivalence, we can count pairs of inconsistent statements she made over this time and write it as $N(t, t^\prime)$ -- in this case $N(10:00, 11:00)$. She hopes this is zero, but it may also be any natural number\footnote{Of course there are biological limits on how fast somebody could assert propositions, but the limits would be very different if Jones were a corporate entity or a computer. It is safer (and methodologically simpler) not to impose an explicit upper bound.}. A continuous span of time between two end-points is known as an \emph{open interval} (for technical reasons we do not include the end-points). 

Imagine that Jones woke up at 7am with a bad headache that lasted until 10:15 on the morning of her testimony. We now have two intervals over which we might ask about her inconsistency, the new one being $N(07:00, 10:15)$, the period during which she was distracted by her sore head. Of course, it is natural to ask about the intersection of these two times or, equivalently, the period when the conjunction of the formulae defining them 
is true -- when she was testifying in court and distracted by her headache. In this case she is concerned about the value of $N(10:00, 10:15)$. 

Thus for every pair of intervals of interest, we should also consider their intersection to be of interest: this is analogous to the deductive rule that $p, q\vdash p\land q$. Note that when two intervals are disjoint their intersection is $\emptyset$; for systematic neatness we define $N(\emptyset) = 0$.

The same, of course, goes for unions. Suppose that Jones was called back to testify again between 3 and 4 in the afternoon. Then she will be concerned about the value of $N(10:00, 11:00)\cup(15:00, 16:00)$ -- that is, how many contradictions she offered up in court altogether. However, this is certainly different from $N(10:00, 16:00)$, which includes statements she made outside court -- contradictions involving these are presumably quite different in nature. Thus we also want to consider unions of pairs of intervals. 

Since unions are not necessarily intervals we adopt the more general term `open set' for any period of time that may be the union or intersection of a pair of open intervals, including the empty set $\emptyset$. `Open' is acting as a technical term here and has no special meaning in relation to the example.

We also allow countably infinite unions so that we can speak of, for example, $N(-\infty, t)$, the number of inconsistencies Jones has uttered up to $t$. In practical terms of course this can be avoided by placing limits on the earliest and latest times we wish to consider -- in Jones's case, the time of her birth and of her death, respectively -- but for a general theory that might involve multiple speakers this is inconvenient. Clearly if $t$ is a time before Jones's first assertion, $N(-\infty, t) = 0$ and this causes no problems.

We do not, however, extend the same courtesy to infinite intersections because these can produce degenerate cases such as `open intervals' consisting of a single temporal instant. Again, for practical purposes these cause no problem but we would prefer not to have to deal with them in a general theory. We will return to the question of infinite intersections later.

\subsection{Formalization}

Let us express the structural features of the situation described in the previous section in more familiar mathematical terms. We will represent time by the real number line $\mathbb{R}$. This need not be the classical real line but we assume it is a one-dimensional continuum that supports normal arithmetic (i.e. a complete ordered field). 

Our open sets exhibit the following important structure:
\begin{defn}
	Let $S$ be a set. Then $T\subseteq 2^S$ is a \emph{topology} on $S$ if and only if the following hold:
	\begin{itemize}
		\item $S\in T$ and $\emptyset \in T$.
		\item For $a, b\in T$ we have $a\cap b\in S$.
		\item For any countable set $A\subseteq T$ we have $\bigcup A\in T$.
	\end{itemize}
	The elements of $T$ are called its \emph{open sets}.
\end{defn}
It makes sense to direct our attention to open sets rather than points. The particular topology we described in the previous section is known as the `Euclidean topology' on $\mathbb{R}$. It arose from our method of measuring inconsistency by $|t-t^\prime |$, and all the questions we were motivated to ask involved the open sets that arise from that measure. We are never concerned with elements of $\mathbb{R}$ themselves, which represent temporal instants (we may even be skeptical of their existence\footnote{If so, this formalization can be adapted to remove points entirely using the localic approach.}). Thus we are really only interested in the open sets and the map $N$, which sends each open set to a natural number, i.e. $N:T\to \mathbb{N}$. In this text $\mathbb{N}$ always includes zero. 

However, not just any map $N:T\to \mathbb{N}$ will do. For example, suppose that we have open sets $V, W$ such that $V\subset W$. Then we must have $N(V)\le N(W)$. Furthermore, we need to be careful that intersections and unions are handled in a consistent way, and this is not so easy to sum up in a single criterion. To describe those maps $N:T\to \mathbb{N}$ that could be inconsistency-counts on time-periods, we need a description of how the values of such a map on multiple time-periods can be `glued together' in a consistent way. This is what the definition of a sheaf will achieve, which is the goal of the remainder of this section.

We now define the basic structure we will use to organise our work. This is an `official definition' but we will not need most of the detail:
\begin{defn}
	A \emph{category} is a set of objects, each of which is thought of as a `point', plus a set of morphisms, each of which is thought of as an `arrow' between two points. The morphisms must satisfy the following criteria:
	\begin{itemize}
		\item Compositions of morphisms always exist. This means that whenever we have a morphism $f:a\to b$ and another $g:b\to c$ we automatically have a third, $g\circ f:a\to c$. (Note the order of this notation!)
		\item Composition of morphisms is associative -- that is, $(f\circ g)\circ h = f\circ (g\to h)$
		\item For each object $a$ there is a morphism $a_i:a\to a$ such that $f\circ a_i = f = a_i\circ f$. Because of this equality, $a_i$ is called the \emph{identity morphism} for $a$.
	\end{itemize}
\end{defn}
In general category theory the objects and/or morphisms of a category might be a proper class, but in this example they will always be sets -- technically we will be dealing only with `small categories'.

We will now define two categories, one of which models the topology of the real line and the other of which models the natural numbers.
\begin{defn}
	Let $(S, T)$ be any topological space. Then there is a category $\boldsymbol{\mathsf{Op}}(T)$, whose objects are the open sets of $T$ and where for each $a, b\in T$ we have a morphism $a\to b$ if and only if $a\subseteq b$.
\end{defn}
We can think of the morphisms in $\boldsymbol{\mathsf{Op}}(T)$ as inclusion maps -- that is, as mapping every element of $a$ to the same element in $b$, which is always possible because $a\subseteq b$. However, it is not necessary to attribute any internal structure to morphisms or objects. Category theory captures their structural inter-relations, not their internals.
\begin{defn}
	There is a category $\boldsymbol{\mathsf{N}}$ whose objects are natural numbers (including zero) and where for each $a, b\in \mathbb{N}$ we have a morphism $a\to b$ if and only if $a\le b$.
\end{defn}
Note that the objects of $\boldsymbol{\mathsf{N}}$ may be construed as sets by the standard construction. Although we are rarely concerned with the internal structure of objects in categories, this is worth bearing in mind when considering definitions (especially of sheaves) given in other sources. Again, under this interpretation we may think of each morphism as the embedding that sends each element to itself.

Our practical example involves some kind of mapping from $\boldsymbol{\mathsf{Op}}(T)$ to $\boldsymbol{\mathsf{N}}$ -- such mappings between categories are called \emph{functors} and are required to satisfy some criteria of good behaviour. First, just like a map between sets, any functor $F:\boldsymbol{\mathsf{Op}}(T)\to \boldsymbol{\mathsf{N}}$ assigns an element of $\boldsymbol{\mathsf{N}}$ to every element of $\boldsymbol{\mathsf{Op}}(T)$. This is the only constraint on a map between sets, but functors must also `respect morphisms' in the following sense:
\begin{itemize}
	\item  $F$ must associate to every morphism in $\boldsymbol{\mathsf{Op}}(T)$ a morphism in $\boldsymbol{\mathsf{N}}$ in such a way that $F(f:a\to b)$ is a morphism $F(f):F(a)\to F(b)$.
	\item $F(a_i) = F(a)_i$ -- that is, identity morphisms should map to identity morphisms.
	\item $F(g\circ f) = F(g)\circ F(f)$ -- that is, the image of the composition should be the composition of the images.
\end{itemize}
In our case, note that these rules already exclude many nonsensical situations. For example, suppose I say that yesterday I contradicted myself once, but yesterday while giving a lecture I did so three times. Write $a$ for yesterday and $b$ for my time giving the lecture, so that $b\subseteq a$. Now the functor that assigns inconsistency counts sends $a\to 1$ and $b\to 3$. However, there is a morphism $b\to a$ in $\boldsymbol{\mathsf{Op}}(T)$ (since $b\subseteq a$) but no corresponding morphism in $\boldsymbol{\mathsf{N}}$ for the functor to send it to. Thus this functor cannot be defined, which is reassuring -- this is because the functor in question is a presheaf\footnote{The usual definition requires us to use the `opposite category' to $\boldsymbol{\mathsf{Op}}(T)$ to obtain a covariant functor, or to define the functor as contravariant. In this case we have ordered the natural numbers in such a way that we get covariance without this step. Certainly we could have defined $\boldsymbol{\mathsf{N}}$ with the opposite morphisms, $a\to b$ if and only if $b\le a$; contravariance would then reappear. This seemed over-complicated in the present context.}.

Any such functor represents a way to assign natural numbers to open sets of $\mathbb{R}$ in a consistent way. Thus, each represents a possible global picture of inconsistency over all possible time-periods.

We would now like to gather up all these functors into a collection. We already have a suitable structure for this: these functors form the objects of a category. The morphisms of this category are the following:
\begin{defn}
	Let $\boldsymbol{\mathsf{A}}$ and $\boldsymbol{\mathsf{B}}$ be categories and let $F:\boldsymbol{\mathsf{A}}\to \boldsymbol{\mathsf{B}}$ and $G:\boldsymbol{\mathsf{A}}\to \boldsymbol{\mathsf{B}}$ be functors from $\boldsymbol{\mathsf{A}}$ to $\boldsymbol{\mathsf{B}}$. Then a \emph{natural transformation} $\Gamma: F\to G$ associates each $F(a)$ with $G(a)$ and each morphism $F(f):F(a)\to F(b)$ with the morphism $G(f):G(a)\to G(b)$. These assignments are required to be mutually consistent.
\end{defn}
This is called the category of \emph{presheaves} on $\boldsymbol{\mathsf{Op}}(T)$ with values in $\boldsymbol{\mathsf{N}}$. There is no requirement, in general, that the `source' category be a topological space or that the `target' category be a set of numbers; as long as the category of functors and their natural transformations can be formed, presheaves are present. The term `presheaf' points to the existence of a `sheaf', which is a more `rigid' object; these are not difficult to define but we will not need them here. 

\subsection{Topos and Intuitionism}

Informally, a topos is any category that has sufficient structural similarities to a category of presheaves. It is a well-known slogan that `the internal logic of a topos is intuitionistic'. This section explains what this means. We motivate the technicalities as far as possible by referring back to our practical example, frequently sacrificing generality in the process. 

It is well-known that the propositions expressible in an intuitionistic theory, ordered by entailment, take the form of a Heyting lattice\footnote{That is, the Lindenbaum-Tarski algebra of an intuitionistic theory is Heyting just as that of a classical theory is Boolean. The equivalent structure for paraconsistent theories is a Brouwerian lattice, which we will discuss further below.}. This is also precisely the form taken by a topology. Hence $\boldsymbol{\mathsf{Op}}(T)$ is a Heyting lattice.

This, however, is not quite what we promised to show. It is only by good fortune that $\boldsymbol{\mathsf{Op}}(T)$ is a topological space; were we dealing with a different problem, we might have arrived at a different structure -- for example, the $\sigma$-algebra structure common in probability, or indeed a Boolean algebra, or perhaps no obvious structure at all. What we will show is that \emph{every} category of presheaves has this structure, and is therefore a model of an intuitionistic theory.

\subsection{Complement Topos and Paraconsistency}



\end{document}